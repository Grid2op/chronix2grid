{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains how to get a first grid2op environment, then use the data it needs to generate some loads and renewables (and a shitty market design) and load this second environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook uses the last version of grid2op. You can install it with:\n",
      "\tC:\\Users\\nmegel\\.virtualenvs\\1_-_Développement-Lgbi9NSE\\Scripts\\python.exe -m pip install grid2op\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"This notebook uses the last version of grid2op. You can install it with:\\n\"\\\n",
    "      \"\\t{} -m pip install grid2op\".format(sys.executable))\n",
    "import grid2op\n",
    "if grid2op.__version__ < \"0.6.0\":\n",
    "    raise RuntimeError(\"Impossible to run this notebook without grid2op version 0.6.0 installed.\")\n",
    "from grid2op.Chronics import ChangeNothing\n",
    "from grid2op.Plot import PlotMatplotlib\n",
    "\n",
    "#path_grid = os.path.join(\"data\", \"case118_l2rpn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronix2grid modules\n",
    "sys.path.insert(0, '..')\n",
    "import generation.generate_chronics as gen\n",
    "import generation.consumption.generate_load as gen_loads\n",
    "import generation.renewable.generate_solar_wind as gen_enr\n",
    "import generation.thermal.generate_dispatch as gen_dispatch\n",
    "import generation.thermal.dispatch_utils as du\n",
    "\n",
    "import generation.dispatch.EconomicDispatch as ec\n",
    "import generation.thermal.EDispatch_L2RPN2020.run_economic_dispatch as run_economic_dispatch\n",
    "import kpi.main as kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isRunCase118=False\n",
    "isRunCase14=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT\n",
    "\n",
    "INPUT_FOLDER = 'generation/input'\n",
    "# Detailed configuration to set in <INPUT_FOLDER>/<CASE>/params.json\n",
    "start_date = \"2012-01-01\"\n",
    "weeks = 1\n",
    "n_scenarios = 1\n",
    "\n",
    "## KPI computation phase\n",
    "KPI_INPUT_FOLDER = 'kpi/input'\n",
    "IMAGES_FOLDER = 'kpi/images'\n",
    "\n",
    "## Generation step of chronix2grid\n",
    "if isRunCase118:\n",
    "    \n",
    "    CASE = 'case118_l2rpn'\n",
    "    path_grid = os.path.join(INPUT_FOLDER, CASE)\n",
    "    grid_path = os.path.join(path_grid, \"L2RPN_2020_case118_redesigned.json\")\n",
    "    OUTPUT_FOLDER = os.path.join('generation/output', CASE)\n",
    "    images_folder = os.path.join(IMAGES_FOLDER, CASE)\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "\n",
    "    #Intermediate folder used by dispatch\n",
    "    dispatch_case_folder = os.path.join(INPUT_FOLDER, CASE, 'dispatch')\n",
    "\n",
    "if isRunCase14:\n",
    "\n",
    "    ## Generation step of chronix2grid\n",
    "    CASE = 'case14_realistic'\n",
    "    path_grid = os.path.join(INPUT_FOLDER, CASE)\n",
    "    grid_path = os.path.join(path_grid, \"case14_realistic.json\")\n",
    "    OUTPUT_FOLDER = 'generation/output/case14'\n",
    "    images_folder = os.path.join(IMAGES_FOLDER, CASE)\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "        \n",
    "    #Intermediate folder used by dispatch\n",
    "    dispatch_case_folder = os.path.join(INPUT_FOLDER, 'dispatch/case14/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispatch Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20min time computation for a year with every generators at monthly resolution --- Fail on month of june\n",
    "#8min time computation for a year with every generators at weekly resolution --- Fail for last 2 weeks of june\n",
    "#10.5min time computation for a year with every generators at daily resolution --- Fail for 17 and 24 of june \n",
    "#=>no thermal on those days, probably due to ramps! But was converging when looking only per carrier type\n",
    "\n",
    "#1min time computation for a year with every carrier at monthly resolution --- Fail on month of june\n",
    "#6min time computation for a year with every carrier at daily resolution --- Fail on month of june\n",
    "\n",
    "\n",
    "# Run the dispatch in the automated process or \"manually\"\n",
    "run_automated_dispatch = True\n",
    "\n",
    "losses_pct = 3.0\n",
    "DispatchByCarrierOnly=False\n",
    "\n",
    "params_opf = {\n",
    "    'step_opf_min': 5,\n",
    "    'mode_opf': 'month',\n",
    "    'reactive_comp': 1.025,\n",
    "    'losses_pct': losses_pct,\n",
    "    'dispatch_by_carrier': DispatchByCarrierOnly\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env118_withoutchron = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                      grid_path=grid_path, # assign it the 118 grid\n",
    "                      chronics_class=ChangeNothing, # tell it to change nothing (not the most usable environment...)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.06\n",
       "Name: vm_pu, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env118_withoutchron.backend._grid.ext_grid.vm_pu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Energy Mix apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the differences in your target energy mix and you energy mix a priori are: 39.961089494163424%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_energy_mix</th>\n",
       "      <th>pmax</th>\n",
       "      <th>capacity_mix</th>\n",
       "      <th>capacity_factor</th>\n",
       "      <th>Apriori_energy_mix</th>\n",
       "      <th>revised_pmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>solar</th>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.420233</td>\n",
       "      <td>68.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.809339</td>\n",
       "      <td>61.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuclear</th>\n",
       "      <td>35</td>\n",
       "      <td>140.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>95.0</td>\n",
       "      <td>51.750973</td>\n",
       "      <td>94.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hydro</th>\n",
       "      <td>15</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.673152</td>\n",
       "      <td>128.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thermal</th>\n",
       "      <td>40</td>\n",
       "      <td>120.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.346304</td>\n",
       "      <td>213.315789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target_energy_mix   pmax  capacity_mix  capacity_factor  \\\n",
       "solar                    4  110.0          20.4             15.0   \n",
       "wind                     6   70.0          13.0             25.0   \n",
       "nuclear                 35  140.0          25.9             95.0   \n",
       "hydro                   15  100.0          18.5             30.0   \n",
       "thermal                 40  120.0          22.2              NaN   \n",
       "\n",
       "         Apriori_energy_mix  revised_pmax  \n",
       "solar              6.420233     68.533333  \n",
       "wind               6.809339     61.680000  \n",
       "nuclear           51.750973     94.684211  \n",
       "hydro             11.673152    128.500000  \n",
       "thermal           23.346304    213.315789  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "Target_EM_percentage=pd.DataFrame(data=[4,6,35,15,40],columns=['target_energy_mix'],\n",
    "                                  index=['solar','wind','nuclear','hydro','thermal'])\n",
    "\n",
    "if isRunCase14:\n",
    "    PeakLoad=308\n",
    "    AverageLoad=257\n",
    "elif isRunCase118:\n",
    "    PeakLoad=4200\n",
    "    AverageLoad=2800\n",
    "    \n",
    "CapacityFactor=pd.DataFrame(data=[15,25,95,30,np.nan],columns=['capacity_factor'],\n",
    "                            index=['solar','wind','nuclear','hydro','thermal'])\n",
    "Capacity_df=EnergyMix_AprioriChecker(env118_withoutchron,Target_EM_percentage, PeakLoad, AverageLoad, CapacityFactor )\n",
    "Capacity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II Generate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can set generation configuration such as number of scenarios, start date, number of weeks, noise intensities, timestep... in INPUT_FOLDER/CASE/params.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II A) Generate loads and renewables\n",
    "\n",
    "Chronix2grid generation process which implements Balthazar method. CSV writting takes long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing parameters ...\n",
      "Importing loads and prods parameters ...\n",
      "2012\n",
      "================ Generating scenario number 0 ================\n",
      "Computing global auto-correlated spatio-temporal noise for thermosensible demand...\n",
      "Computing loads ...\n",
      "Saving files in zipped csv in \"generation/input\\dispatch/case14/2012\\Scenario_0\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Reading parameters\n",
    "year, params, loads_charac, prods_charac, load_weekly_pattern, solar_pattern, lines = gen.read_configuration(INPUT_FOLDER, CASE, start_date, weeks)\n",
    "print(year)\n",
    "\n",
    "## Whole generation\n",
    "# gen.main(year, n_scenarios, params, INPUT_FOLDER, OUTPUT_FOLDER, prods_charac, loads_charac, lines, solar_pattern, load_weekly_pattern)\n",
    "\n",
    "\n",
    "## OR ============\n",
    "\n",
    "# Separate generation for load and renewables\n",
    "\n",
    "\n",
    "# Create folders\n",
    "dispatch_input_folder = os.path.join(dispatch_case_folder, str(year))\n",
    "dispatch_output_folder = os.path.join(OUTPUT_FOLDER, str(year))\n",
    "os.makedirs(dispatch_input_folder, exist_ok=True)\n",
    "os.makedirs(dispatch_output_folder, exist_ok=True)\n",
    "\n",
    "# Make sure the seeds are the same, whether computation is parallel or sequential\n",
    "seeds = [np.random.randint(low=0, high=2**31) for _ in range(n_scenarios)]\n",
    "\n",
    "\n",
    "# Launch load generation\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(\"================ Generating scenario number \"+str(i)+\" ================\")\n",
    "    load, load_forecasted = gen_loads.main(i, dispatch_input_folder, seed, params, loads_charac, \n",
    "                                           load_weekly_pattern, write_results = True)\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex‚cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!ls $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check load hypothesis (peak and average)\n",
    "\n",
    "**if this differs by too much, you should update the computation of the Energy Mix a priori and revise some calibration if not satisfactory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the expected peak load was: 308\n",
      "the actual peak load is: 307.6037955988748\n"
     ]
    }
   ],
   "source": [
    "CurrentPeakLoad=load.sum(axis=1).max()\n",
    "print('the expected peak load was: '+str(PeakLoad))\n",
    "print('the actual peak load is: '+str(CurrentPeakLoad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the expected average load was: 257\n",
      "the actual average load is: 255.56511461488537\n"
     ]
    }
   ],
   "source": [
    "CurrentAverageLoad=load.sum(axis=1).mean()\n",
    "print('the expected average load was: '+str(AverageLoad))\n",
    "print('the actual average load is: '+str(CurrentAverageLoad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Renewables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Generating scenario number 0 ================\n",
      "Computing global auto-correlated spatio-temporal noise for sun and wind...\n",
      "Generating solar and wind production chronics\n",
      "Saving files in zipped csv\n",
      "Preprocessing input data..\n",
      "Filter generators ramps up/down\n",
      "Adapting PyPSA grid with parameters..\n",
      "\n",
      "--> OPF formulation by => month - Analyzing month # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pypsa.linopf:Prepare linear problem\n",
      "INFO:pypsa.linopf:Total preparation time: 0.18s\n",
      "INFO:pypsa.linopf:Solve linear problem using Cbc solver\n",
      "INFO:pypsa.linopf:Optimization successful. Objective value: 1.04e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- opf succeeded  >Objective value (should be greater than zero!\n",
      "Total time 0.03 min\n",
      "OPF Done......\n",
      "Saving results for the grids with individual generators...\n",
      "Saving chronics into generation/output/case14\\2012\\Scenario_0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dispatcher = ec.Dispatcher.from_gri2op_env(env118_withoutchron)\n",
    "\n",
    "# move the 2 following lines inside the loop if they should be different for each scenario\n",
    "dispatcher.modify_marginal_costs({'hydro': 3, 'nuclear': 8})\n",
    "dispatcher.read_hydro_guide_curves(os.path.join(INPUT_FOLDER, 'patterns', 'hydro_french.csv'))\n",
    "\n",
    "# Launch solar and wind generation\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(\"================ Generating scenario number \"+str(i)+\" ================\")\n",
    "    \n",
    "    scenario_name = f'Scenario_{i}'\n",
    "    input_scenario_folder, output_scneario_folder = du.make_scenario_input_output_directories(\n",
    "        dispatch_input_folder, dispatch_output_folder, scenario_name)\n",
    "    \n",
    "    prod_solar, prod_solar_forecasted, prod_wind, prod_wind_forecasted = gen_enr.main(i, dispatch_input_folder, seed,params, prods_charac, solar_pattern, \n",
    "                                                                                 write_results = True)\n",
    "    \n",
    "    if run_automated_dispatch:\n",
    "        prods = pd.concat([prod_solar, prod_wind], axis=1)\n",
    "        res_names = dict(wind=prod_wind.columns, solar=prod_solar.columns)\n",
    "        dispatcher.chronix_scenario = ec.ChroniXScenario(load, prods, res_names, scenario_name)\n",
    "\n",
    "        dispatch_results = gen_dispatch.main(dispatcher, input_scenario_folder, output_scneario_folder, \n",
    "                                             seed, params_opf)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls generation/output/case14/2012/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading parameters\n",
    "#year, n_scenarios, params, loads_charac, prods_charac, load_weekly_pattern, solar_pattern, lines = gen.read_configuration(INPUT_FOLDER, CASE)\n",
    "#print(year)\n",
    "#gen.main(year, n_scenarios, params, INPUT_FOLDER, OUTPUT_FOLDER, prods_charac, loads_charac, lines, solar_pattern, load_weekly_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26172fa8d48>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(solar_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Ramps and Pmin/Pmax Generator parameters A priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the scenario you want to check first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "\n",
    "losses_pct = 3.0  # losses as pct of load\n",
    "[isThermalInTrouble,isNuclearInTrouble,IsRampUpInTrouble,IsRampDownInTrouble]=Ramps_Pmax_Pmin_APrioriCheckers(\n",
    "    env118_withoutchron,Capacity_df,dispatch_input_folder,losses_pct,PeakLoad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Are the thermal reactors \\\"in trouble\\\": {}\".format(isThermalInTrouble))\n",
    "print(\"Are the nuclear reactors \\\"in trouble\\\": {}\".format(isNuclearInTrouble))\n",
    "print(\"Are the ramp up \\\"in trouble\\\": {}\".format(IsRampUpInTrouble))\n",
    "print(\"Are the ramp down \\\"in trouble\\\": {}\".format(IsRampDownInTrouble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "Aposteriori_renewableCapacityFactor_Checkers(env118_withoutchron,Capacity_df, dispatch_input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute some KPIs for solar, wind and load\n",
    "\n",
    "#### Good comparison can be obtained by setting \"renewable_ninja\" as comparison in KPI_INPUT_FOLDER/paramsKPI.json\n",
    "Images are saved in IMAGES_FOLDER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind_solar_only = True\n",
    "# if not os.path.exists(KPI_INPUT_FOLDER):\n",
    "#     os.mkdir(KPI_INPUT_FOLDER)\n",
    "# kpis.main(KPI_INPUT_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, images_folder, year, CASE, n_scenarios, wind_solar_only, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create The EconomicDispatch instance : a high level wrapper around a Pypsa net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install PyPSA correctly <br>\n",
    "`pip3 install -U git+http://github.com/PyPSA/PyPSA.git@8d527e25fa9876cac66957448f449a1c901901d2`\n",
    "\n",
    "You also need to install the solver that pypsa is calling. For instance cbc solver. On Fedora do `dnf install coin-or-Cbc.x86_64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import generation.dispatch.EconomicDispatch as ec\n",
    "import generation.thermal.EDispatch_L2RPN2020.run_economic_dispatch as run_economic_dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatcher = ec.Dispatcher.from_gri2op_env(env118_withoutchron)\n",
    "dispatcher.modify_marginal_costs({'hydro': 3, 'nuclear': 8})\n",
    "dispatcher.read_hydro_guide_curves(os.path.join(INPUT_FOLDER, 'patterns', 'hydro_french.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatcher.plot_ramps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II B) Run a unit commitment model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use pypsa. To avoid messing with the names, and make sure to have data in the proper shape, it is better, I think, to create the pypsa network directly from the grid2op environment.\n",
    "\n",
    "For more information on unit commitment see https://pypsa.org/examples/unit-commitment.html for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run opf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not run_automated_dispatch:\n",
    "\n",
    "    # The run is by scenario\n",
    "    for subpath in os.listdir(dispatch_input_folder):\n",
    "\n",
    "        if subpath in ['.DS_Store']:\n",
    "            continue\n",
    "\n",
    "        this_path = os.path.join(dispatch_input_folder, subpath)\n",
    "        dispatcher.read_load_and_res_scenario(os.path.join(this_path, 'load_p.csv.bz2'),\n",
    "                                            os.path.join(this_path, 'prod_p.csv.bz2'),\n",
    "                                            scenario_name=subpath)\n",
    "        hydro_constraints = dispatcher.make_hydro_constraints_from_res_load_scenario()\n",
    "        agg_load_without_renew = dispatcher.net_load(losses_pct, name=dispatcher.loads.index[0])\n",
    "\n",
    "        # Example of how to extract info on the largest ramps\n",
    "        print(f'5 largest ramps reached by the agg_load_without_renew:')\n",
    "        print(dispatcher.nlargest_ramps(5, losses_pct))\n",
    "\n",
    "        # Run Economic Disptach using submodule EDisptach_L2RPN_2020\n",
    "        # **  **  **  **  **  **  **  **  **  **  **  **  **  **\n",
    "        dispatch_results = dispatcher.run(\n",
    "                                            agg_load_without_renew,\n",
    "                                            params=params_opf,\n",
    "                                            gen_constraints=hydro_constraints,\n",
    "                                            ramp_mode=run_economic_dispatch.RampMode.none,\n",
    "                                            by_carrier=DispatchByCarrierOnly  # True to run the dispatch only aggregated generators by carrier\n",
    "                                        )\n",
    "\n",
    "        chronix_scenario = dispatch_results.chronix\n",
    "\n",
    "        # save prods chronics\n",
    "        dispatcher.save_results(dispatch_output_folder)\n",
    "\n",
    "        #TODO this should not be done in the notebook, but in chronix2grid ! These files are output of chronix2grid.\n",
    "        import shutil\n",
    "        shutil.copy(os.path.join(dispatch_input_folder, subpath, 'load_p_forecasted.csv.bz2'),\n",
    "                    os.path.join(dispatch_output_folder, subpath, 'chronics', 'load_p_forecasted.csv.bz2'))\n",
    "        shutil.copy(os.path.join(dispatch_input_folder, subpath, 'wind_p_forecasted.csv.bz2'),\n",
    "                    os.path.join(dispatch_output_folder, subpath, 'chronics', 'wind_p_forecasted.csv.bz2'))\n",
    "        shutil.copy(os.path.join(dispatch_input_folder, subpath, 'solar_p_forecasted.csv.bz2'),\n",
    "                    os.path.join(dispatch_output_folder, subpath, 'chronics', 'solar_p_forecasted.csv.bz2'))\n",
    "\n",
    "    # TODO if there are failures, write it somewhere, for now it's only detected in the very verbose output cell.\n",
    "    # for example you can do a report at the end 'looking like failures for scenariis xxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chronix_scenario is an object containing all the time series related to the studied scenario : \n",
    "- chronix_scenario.name gives the name of the scenario\n",
    "- chronix_scenario.wind_p (resp. solar_p, prods_dispatch, loads, marginal_prices) gives the Wind DataFrame (resp. Solar, Dispatched generators, loads, marginal_prices)\n",
    "\n",
    "This object should be manipulated in the sequel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that the max net load is similar than after generating loads and renewables\n",
    "agg_load_without_renew.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate renewable dispatch\n",
    "\n",
    "#Becareful:check years of opf_dispatch and dispatch\n",
    "print(chronix_scenario.wind_p.index[0])\n",
    "print(chronix_scenario.prods_dispatch.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(chronix_scenario.wind_p.index[0] != chronix_scenario.prods_dispatch.index[0]):\n",
    "    chronix_scenario.prods_dispatch.index=chronix_scenario.wind_p.index\n",
    "if DispatchByCarrierOnly:\n",
    "    chronix_scenario.prods_dispatch=chronix_scenario.prods_dispatch[['nuclear','hydro','thermal']]#makesure nuclear comesfirst, for good plotting after\n",
    "\n",
    "full_opf_dispatch = pd.concat(\n",
    "    [chronix_scenario.prods_dispatch, chronix_scenario.wind_p, chronix_scenario.solar_p],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Keep same order as grid2op\n",
    "if not DispatchByCarrierOnly:\n",
    "    full_opf_dispatch = full_opf_dispatch[env118_withoutchron.name_gen].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env118_withoutchron.name_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DispatchByCarrierOnly:\n",
    "    nuclear_names = dispatcher.generators[dispatcher.generators.carrier == 'nuclear'].index\n",
    "    hydro_names = dispatcher.generators[dispatcher.generators.carrier == 'hydro'].index\n",
    "    thermal_names = dispatcher.generators[dispatcher.generators.carrier == 'thermal'].index\n",
    "\n",
    "    dispatch_by_fleet=pd.concat([ dispatcher.wind_p, dispatcher.solar_p], axis=1)\n",
    "    dispatch_by_fleet['nuclear'] = full_opf_dispatch[nuclear_names].sum(axis=1).to_frame('Nuclear')\n",
    "    dispatch_by_fleet['hydro'] = full_opf_dispatch[hydro_names].sum(axis=1)\n",
    "    dispatch_by_fleet['thermal'] = full_opf_dispatch[thermal_names].sum(axis=1)\n",
    "    #dispatch_by_fleet=pd.concat([dispatch_by_fleet, dispatch.wind_p, dispatch.solar_p], axis=1)\n",
    "\n",
    "    dispatch_by_fleet.loc[dispatch_by_fleet['thermal'] < 0, 'thermal'] = 0\n",
    "\n",
    "    # grid2op env starts in 2007 but read loads are in 2012...\n",
    "    #dispatch_by_fleet = dispatch_by_fleet.loc[dispatch_by_fleet.index.year == 2007,:]\n",
    "\n",
    "    dispatch_by_fleet.plot(figsize=(20, 8), title='Dispatch over 1 year', kind='area')\n",
    "\n",
    "else:\n",
    "    dispatch_by_fleet=full_opf_dispatch\n",
    "    \n",
    "    dispatch_by_fleet.loc[dispatch_by_fleet['thermal'] < 0, 'thermal'] = 0 #due to numeric approximation,some thermal values  could be negative\n",
    "    dispatch_by_fleet.loc[dispatch_by_fleet['hydro'] < 0, 'hydro'] = 0\n",
    "    #full_opf_dispatch[full_opf_dispatch['thermal']<0]['thermal'].hist()\n",
    "    dispatch_by_fleet.plot(figsize=(20, 8), title='Dispatch over 1 year', kind='area')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet[['nuclear','hydro','thermal']].plot(figsize=(20, 8), title='Dispatch over 1 year - no renewable', kind='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeekNumber=24\n",
    "dispatch_by_fleet.iloc[(288*7*WeekNumber):(288*7*(WeekNumber+1)), :].plot(figsize=(20, 8), title='Dispatch over 1 week', kind='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet[['nuclear','hydro','thermal']].iloc[(288*7*WeekNumber):(288*7*(WeekNumber+1)), :].plot(figsize=(20, 8), title='Dispatch over 1 week - no renewable', kind='area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Hydro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In june, Hydro might be high and the minimum hydro production to respect forces nuclear to decrease its production\n",
    "if not(dispatch_by_fleet[['hydro']].sum().values==0):\n",
    "    minHydroPattern=dispatcher._min_hydro_pu\n",
    "    nCols=minHydroPattern.shape[1]\n",
    "    minHydroPattern.iloc[:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In june, Hydro might be high and the minimum hydro production to respect forces nuclear to decrease its production\n",
    "if not(dispatch_by_fleet[['hydro']].sum().values==0):\n",
    "    maxHydroPattern=dispatcher._max_hydro_pu\n",
    "    nCols=maxHydroPattern.shape[1]\n",
    "    maxHydroPattern.iloc[:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate whether they have same order\n",
    "np.all(full_opf_dispatch.columns == env118_withoutchron.name_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Energy Mix of Dispatch and capacity factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentAverageLoad=load.sum(axis=1).mean()\n",
    "dispatch_by_fleet[['nuclear','hydro','thermal']].mean()/CurrentAverageLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet[['nuclear','hydro','thermal']].mean()/dispatch_by_fleet[['nuclear','hydro','thermal']].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute some KPIs for dispatch\n",
    "As I never had a dispatch output file, I didn't have a precise output format for the dispatch to be taken into account by the KPI module.So I chose to take the format of the only example i had: chronics exported by a previous script of Camilo with month by month dispatch chronics. \n",
    "- Download these files to have a format example on Nextcloud: https://nextcloud.artelys.com/nextcloud/s/tFirA3TRXrHeFwC\n",
    "- Careful, this example is for year 2007\n",
    "- We should agree on an output format from dispatch. Maybe you could put it on Nextcloud as an example for me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You have to set \"eco2mix\" as comparison in KPI_INPUT_FOLDER/paramsKPI.json\n",
    "**Images were not designed to be plot on a notebook but to be saved as png or zoomable in IMAGES_FOLDER**. In particular, yearly productions and energy mix are better to watch in their written files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "wind_solar_only = False\n",
    "kpis.main(KPI_INPUT_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, images_folder, year, CASE, n_scenarios, wind_solar_only, params, loads_charac, prods_charac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III Create an environment with the chronics this time\n",
    "\n",
    "This is to test the environment can be used by grid2op. This is what the \"case118_l2rpn\" will look like for the competitions.\n",
    "\n",
    "**NB** The \"Balthazar code\" is fully compatible with the \"GridStateFromFileWithForecasts\". So it is useful to use this class to load back the data. If the data generation process does not provide the same utilities, it is not a problem to write another class, like \"GridStateFromFileWithForecasts\" that can read its format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the bug in element 7_4_173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO YOU SHOULD NOT DO THAT BUT BE ABLE TO RUN ALL SCENARIOS IN THE RUNNER.\n",
    "\n",
    "# Chose generated scenario\n",
    "# scenario = 'Scenario_15'\n",
    "# scenario_path = os.path.join(OUTPUT_FOLDER, str(year), scenario)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I can't run from the following cell: can't make the dispatch run on my machine and don't data in the right format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from grid2op.Chronics import Multifolder, GridStateFromFileWithForecasts\n",
    "from grid2op.Parameters import Parameters\n",
    "try:\n",
    "    from pyklu2grid.PyKLUBackend import PyKLUBackend\n",
    "    backend = PyKLUBackend()\n",
    "except:\n",
    "    from grid2op.Backend import PandaPowerBackend\n",
    "    backend = PandaPowerBackend()\n",
    "    print(\"You might need to install the pklu backend (provisory name) to gain massive speed up\")\n",
    "# don't disconnect powerline on overflow, the thermal limit are not set for now, it would not make sens\n",
    "param = Parameters()\n",
    "param.init_from_dict({\"NO_OVERFLOW_DISCONNECTION\": True})\n",
    "\n",
    "env = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                   grid_path=grid_path, # assign it the 118 grid\n",
    "                   chronics_class=Multifolder, # tell it to change nothing (not the most usable environment...)\n",
    "                   data_feeding_kwargs= {\n",
    "                       \"path\": os.path.abspath(dispatch_output_folder), \"gridvalueClass\": GridStateFromFileWithForecasts},\n",
    "                   param=param,\n",
    "                   backend=backend\n",
    "                  )\n",
    "# If you remove the \"GridStateFromFileWithForecasts\", from above, chronics will NOT be loaded properly.\n",
    "# GridStateFromFileWithForecasts is the format used for the competition, so it is mandatory that this works!\n",
    "# WITHOUT ANY MODIFICATIONS\n",
    "\n",
    "# Beside the environment should be able to load all data generated, and not one episode.\n",
    "# so please look in grid2op for compatible formats. This is not a valid format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set env thermal limit to 1 by default\n",
    "th_lim = np.ones(env.n_line, dtype=np.float)\n",
    "env.set_thermal_limit(th_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can test that we can use a Runner, store the results, and plot the flows on the powerline for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Validate the generation process\n",
    "\n",
    "For that we use a runner, that will compute the powerflows with a \"do nothing\" agent, and we prevent it to disconnect any power line, even if they are on overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Runner import Runner\n",
    "import tempfile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "path_data_saved = os.path.join(os.path.abspath(os.path.join(output_scneario_folder, os.pardir)), 'agent_results', scenario_name)\n",
    "os.makedirs(path_data_saved, exist_ok=True)\n",
    "\n",
    "nb_episode = 1\n",
    "#nb_steps = 400\n",
    "runner = Runner(**env.get_params_for_runner())\n",
    "\n",
    "# here you might need to change \"nb_episode\" if you generated more than one scenario\n",
    "# this might really take some times... 4 mins per scenario per week [on one core]\n",
    "res = runner.run(nb_episode=nb_episode, path_save=path_data_saved, pbar=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $path_data_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can study the results, for example by loading the chronics, extracting prod p, load p etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.EpisodeData import EpisodeData\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_this_episode = EpisodeData.from_disk(path_data_saved, \"Scenario_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_a = np.array([obs.a_or for obs in data_this_episode.observations])\n",
    "loads_p = np.array([obs.load_p for obs in data_this_episode.observations])\n",
    "prods_p = np.array([obs.prod_p for obs in data_this_episode.observations])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display distribution of flows over scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_ = plt.hist(flows_a,bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the KPI you want with that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to **II)** if results are not satisfying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V Export the final results\n",
    "\n",
    "First, regenerate a lot more data, then save then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO generate more data with the same distribution as the one that has been validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO export them to be usable in a friendly manner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rte-challenge",
   "language": "python",
   "name": "rte-challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "env_for_pypsa"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "env_for_pypsa"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "rte-challenge"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "rte-challenge"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
